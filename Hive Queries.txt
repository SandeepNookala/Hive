
**************   HIVE  ****************


1.Select Query:
------------------
select * from employee;


2.Details of table:
--------------------
describe employee;

describe formatted employee;

3.limit:
--------
select * from employee limit 5;

select * from employee limit 5;


4.alter statments:
==================

Rename table:
---------------
alter table new rename to new_emp;


add new columns to table:
-------------------------

alter table new_emp add columns(location varchar(20));
alter table new_emp  add columns (city varchar(20));


drop table column:
------------------

can't drop column in hive table.


change position of columns:
----------------------------
alter table new_emp change column job job varchar(20) after city;



change name of column:
----------------------
alter table new_emp change column name fname varchar(20);

alter table new_emp change column deptno dept_id int;



5.Create new table from old table with sechema and data:
------------------------------------------------------
create table emp as select empid,fname,salary from employee;


6.Create new table from old table with sechema and without data:
--------------------------------------------------------------
create table updated_emp like employee;
create table update as select * from employee where 1=2; #trigger map reduce job


7.order by :
----------
select * from employee order by salary;

8.order by :
----------
select * from employee sort by salary;

9.group by:
---------

select sum(salary),dept from employee group by dept;

10.Inner join :
----------------

select employee.* ,dept.* 
from employee 
join dept
on employee.empid = dept.deptid ;

11.left join :
----------------

select employee.* ,dept.*
from employee
left join dept 
on employee.empid = dept.deptid ;

12.right join:
--------------

select employee.* ,dept.*
from employee
right join dept 
on employee.empid = dept.deptid ;

13.full join:
--------------

select employee.* ,dept.*
from employee
full join dept
on employee.empid = dept.deptid ;


14.Hive Incremental Load:
=========================

create table temp as
select t2.id,t2.firstname,t2.lastname,t2.updated_date
from ( select *,row_number() over(partition by id order by updated_date desc)rn
from ( select * from day1
union all
select * from day2)
t1)t2
where rn =1;

overwrite:
----------
insert overwrite table day1 select * from temp;

drop:
-----

drop table temp;

15.create external partition table:
====================================

create external table employee_parti(
emp_id int,
name varchar(20),
manager_id int,
hire_date varchar(20),
salary int,
deptno int,
updated_date varchar(20))
partitioned by (job varchar(20))
location '/user/hive/External/employee_parti';


16. load data in partition table:
=================================
set hive.exec.dynamic.partition.mode=nonstrict;
insert into table employee_parti partition(job) select * from employee;
insert overwrite table employee_parti partition(job) select * from employee;


17.show partition of a table:
==========================
show partitions employee_parti;


18.Bucketing table:
================
create external table employee_buck(
emp_id int,
name varchar(20),
manager_id int,
hire_date varchar(20),
salary int,
deptno int,
updated_date varchar(20),
job varchar(20))
clustered by (job) into 5 buckets
location '/user/hive/External/employee_buck';

19. load data in bucketing table:
=================================
set hive.enforce.bucketing = true;

insert into table employee_buck select * from employee;



20.window/Analitical functions:
------------------

row_number():
===========

select *,row_number() over(order by salary desc) rn from employee;


rank():
=======

select *,rank() over(order by salary desc)rk from employee;

dense_rank():
=============
select *,dense_rank() over(order by salary desc) from employee;



