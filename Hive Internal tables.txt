Creating Hive internal tables:
------------------------------
internal employee table:
=======================

create table employee(
emp_id int,
name varchar(20),
manager_id int,
hire_date varchar(20),
salary int,
deptno int,
updated_date varchar(20),
job varchar(20))
row format delimited
fields terminated by ','
lines terminated by '\n' ;

employee seed data:
-------------------
7369,SMITH,7902,17-12-1980,800,20,01-01-2022,CLERK
7499,ALLEN,7698,20-02-1981,1600,30,02-01-2022,SALESMAN
7521,WARD,7698,22-02-1981,1250,30,03-01-2022,SALESMAN
7566,JONES,7839,04-02-1981,2975,20,04-01-2022,MANAGER
7654,MARTIN,7698,21-09-1981,1250,30,05-01-2022,SALESMAN
7698,SGR,7839,05-01-1981,2850,30,06-01-2022,MANAGER
7782,RAVI,7839,06-09-1981,2450,10,07-01-2022,MANAGER
7788,SCOTT,7566,19-04-1987,3000,20,08-01-2022,ANALYST
7839,KING,null,null,5000,10,null,PRESIDENT
7844,TURNER,7698,09-08-1981,1500,30,01-02-2022,SALESMAN
7876,ADAMS,7788,23-05-1987,1100,20,02-02-2022,CLERK
7900,JAMES,7698,12-03-1981,950,30,03-02-2022,CLERK
7902,FORD,7566,12-03-1981,3000,20,04-02-2022,ANALYST
7934,MILLER,7782,01-03-1982,1300,10,05-02-2022,CLERK
1234,SEKHAR,7777,null,667,80,06-02-2022,doctor
1234,RAM,7457,null,494,80,03-01-2021,CLERK


Hive internal dept tables:
------------------------------
Create table dept(
deptid int,
Age int,
Dept varchar(20))
row format delimited fields terminated by '~';


dept seed data:
-------------------
1002~29~MARKETING
1003~30~HR
1005~31~SALES
1006~27~MARKETING
1007~26~HR
1010~32~HR
1011~33~MARKETING
1012~26~ADMIN
1011~32~ADMIN
1013~33~ADMIN


Create table using Advance datatypes:
------------------------------------
Advance Data types:
-------------------
1.Array
2.map
3.struct


create table personal_info(
perid int,
location array<string> ,
contact map<string,int> ,
other_info struct<company:string,salary:int,location:string>)
row format delimited
fields terminated by '$'
collection items terminated by ','
map keys terminated by ':'
lines terminated by '\n';

personal_info seed data:
-----------------------

1001$DELHI,INDIA$CODE:91,MOBILE:797900$TCS,10000,BANGALORE
1002$DELHI,INDIA$CODE:92,MOBILE:6969000$WIPRO,12000,BANGALORE
1003$MUMBAI,INDIA$CODE:93,MOBILE:595900$HCL,13000,AUSTRALIA
1004$HYDERABAD,INDIA$CODE:94,MOBILE:494900$INFOSYS,1500,HYDERABAD
1005$LUCKNOW,INDIA$CODE:95,MOBILE:393900$SHEARFORCE,1200,HYDERABAD
1006$TOKYO,JAPAN$CODE:96,MOBILE:292900$GOOGLE,100000,AUSTRALIA
1010$MELBOURNE,AUSTRALIA$CODE:97,MOBILE:796900$FACEBOOK,120000,USA
1011$SINGAPORE,SINGAPORE$CODE:98,MOBILE:795900$INSTAGRAM,110000,USA

load data inpath '/user/cloudera/personal.txt' overwrite into table personal_info;


Incremental load tables:
------------------------

Day1:
=====

CREATE TABLE Day1
(
ID INT,
FIRSTNAME VARCHAR(100),
LASTNAME VARCHAR(100),
updated_date date 
)
row format delimited fields terminated by ','
lines terminated by '\n';

seed data day1:
---------------
1,aaaa,bbbb,2019-06-20
2,cccc,dddd,2019-06-20
3,eeee,ffff,2019-06-20
4,gggg,hhhh,2019-06-20
5,iiii,jjjj,2019-06-20

loading data:
------------
hdfs dfs -put day1.txt /user/cloudera
load data inpath '/user/cloudera/day1.txt' overwrite into table day1;


Day2:
=====
CREATE TABLE day2
(
ID INT,
FirstName VARCHAR(100),
LastName VARCHAR(100),
updated_date date 
)
row format delimited fields terminated by ','
lines terminated by '\n';

seed data demo2:
----------------
2,bbbb,kkkk,2020-06-20
3,cccc,llll,2020-06-20
 






